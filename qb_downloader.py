#!/usr/bin/env python3
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          KCT QUESTION BANK â€” BULK DOWNLOADER & ORGANIZER v2.0              â•‘
â•‘  High-speed async downloader with live stats, PDF parsing & auto-sorting   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Downloads PDFs from: https://library.kct.ac.in/opac-tmpl/bootstrap/QB/QB{id}.pdf
Traverses IDs 13000â€“14000, extracts course codes starting with 'U',
and organizes into: {Regulation}Regulation/{Dept} Department/{CourseCode}.pdf

Author : Auto-generated by Senior Python Automation Engineer
Date   : 2026-02-18
"""

import asyncio
import os
import re
import sys
import time
from collections import defaultdict
from dataclasses import dataclass, field
from pathlib import Path

import aiofiles
import aiohttp
import fitz  # PyMuPDF â€” fastest PDF text extraction

from rich.console import Console
from rich.live import Live
from rich.table import Table
from rich.panel import Panel
from rich.progress import (
    Progress,
    SpinnerColumn,
    BarColumn,
    TextColumn,
    TimeElapsedColumn,
    TimeRemainingColumn,
    MofNCompleteColumn,
)
from rich.layout import Layout
from rich.text import Text
from rich import box

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONFIGURATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

BASE_URL = "https://library.kct.ac.in/opac-tmpl/bootstrap/QB/QB{qid}.pdf"
START_ID = 11000
END_ID = 12999
OUTPUT_DIR = Path(__file__).parent / "QuestionPapers"
TEMP_DIR = Path(__file__).parent / ".qb_temp"

# Performance tuning
MAX_CONCURRENT = 40          # simultaneous downloads (tune to network)
BATCH_SIZE = 100             # process in batches for memory efficiency
CONNECTOR_LIMIT = 60         # TCP connector pool size
TIMEOUT_SECONDS = 30         # per-request timeout
MAX_RETRIES = 2              # retry failed downloads
CHUNK_SIZE = 65536           # 64KB download chunks

# Course code pattern: U<2-digit reg><2+ letter dept/subject code><digits>
# Examples: U18MEE0034, U21CSE0101, U18EIE0025, U18ECI645
# Department is ALWAYS the first 2 letters after U+regulation
COURSE_CODE_PATTERN = re.compile(
    r'\b(U\d{2}[A-Z]{2,4}\d{3,5})\b'
)

# Department is always first 2 letters â€” no mapping needed, just slice.
# This dict provides human-readable names for known 2-letter dept codes.
DEPT_NAMES = {
    "ME": "ME Department",
    "CS": "CS Department",
    "EC": "EC Department",
    "EE": "EE Department",
    "EI": "EI Department",
    "MC": "MC Department",
    "IT": "IT Department",
    "CE": "CE Department",
    "CI": "CI Department",
    "AI": "AI Department",
    "AD": "AD Department",
    "BM": "BM Department",
    "CH": "CH Department",
    "AU": "AU Department",
    "TE": "TE Department",
    "FT": "FT Department",
    "EN": "EN Department",
    "MA": "MA Department",
    "PH": "PH Department",
    "CY": "CY Department",
    "HS": "HS Department",
    "GE": "GE Department",
    "MR": "MR Department",
    "RO": "RO Department",
    "MT": "MT Department",
    "SE": "SE Department",
    "SF": "SF Department",
    "TX": "TX Department",
    "PR": "PR Department",
    "BT": "BT Department",
    "IS": "IS Department",
    "AE": "AE Department",
    "MB": "MB Department",
    "TL": "TL Department",
}

console = Console()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATA CLASSES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class Stats:
    """Live statistics tracker."""
    total: int = 0
    downloaded: int = 0
    not_found: int = 0
    failed: int = 0
    organized: int = 0
    skipped_non_u: int = 0
    skipped_no_code: int = 0
    retried: int = 0
    bytes_downloaded: int = 0
    start_time: float = 0.0
    dept_counts: dict = field(default_factory=lambda: defaultdict(int))
    reg_counts: dict = field(default_factory=lambda: defaultdict(int))
    errors: list = field(default_factory=list)

    @property
    def elapsed(self) -> float:
        return time.time() - self.start_time if self.start_time else 0

    @property
    def speed_mbps(self) -> float:
        elapsed = self.elapsed
        if elapsed == 0:
            return 0
        return (self.bytes_downloaded / (1024 * 1024)) / elapsed

    @property
    def papers_per_sec(self) -> float:
        elapsed = self.elapsed
        if elapsed == 0:
            return 0
        return self.downloaded / elapsed

    @property
    def progress_pct(self) -> float:
        if self.total == 0:
            return 0
        processed = self.downloaded + self.not_found + self.failed
        return (processed / self.total) * 100


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CORE ENGINE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_course_code(pdf_bytes: bytes) -> str | None:
    """
    Extract course code starting with 'U' from PDF bytes using PyMuPDF.
    Extremely fast â€” processes in-memory without disk I/O.
    """
    try:
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        for page_num in range(len(doc)):
            page = doc[page_num]
            text = page.get_text("text")
            matches = COURSE_CODE_PATTERN.findall(text)
            if matches:
                doc.close()
                return matches[0]  # Return first valid match
        doc.close()
    except Exception:
        pass
    return None


def get_dept_from_code(course_code: str) -> tuple[str, str]:
    """
    Parse course code to extract regulation and department.
    Department is ALWAYS the first 2 letters after U + 2-digit regulation.
    U18MEE0034 â†’ regulation='18', dept='ME'  (NOT 'MEE')
    U18ECI645  â†’ regulation='18', dept='EC'  (NOT 'ECI')
    """
    # U + 2-digit regulation + 2-letter dept + rest
    match = re.match(r'^U(\d{2})([A-Z]{2})', course_code)
    if not match:
        return "Unknown", "Unknown Department"

    regulation = match.group(1)
    dept_code = match.group(2)  # Always exactly 2 letters

    dept_folder = DEPT_NAMES.get(dept_code, f"{dept_code} Department")
    return regulation, dept_folder


def organize_file(pdf_bytes: bytes, course_code: str, stats: Stats) -> Path | None:
    """Place PDF in the correct nested folder structure."""
    regulation, dept_folder = get_dept_from_code(course_code)
    reg_folder = f"{regulation}Regulation"

    target_dir = OUTPUT_DIR / reg_folder / dept_folder
    target_dir.mkdir(parents=True, exist_ok=True)

    target_path = target_dir / f"{course_code}.pdf"

    # If file already exists with same course code, add QB id suffix
    if target_path.exists():
        # File already organized â€” skip duplicate
        return target_path

    with open(target_path, "wb") as f:
        f.write(pdf_bytes)

    stats.dept_counts[dept_folder] += 1
    stats.reg_counts[reg_folder] += 1
    stats.organized += 1
    return target_path


async def download_one(
    session: aiohttp.ClientSession,
    qid: int,
    semaphore: asyncio.Semaphore,
    stats: Stats,
    progress: Progress,
    task_id,
) -> None:
    """Download a single PDF, extract course code, and organize."""
    url = BASE_URL.format(qid=qid)

    async with semaphore:
        for attempt in range(MAX_RETRIES + 1):
            try:
                async with session.get(url) as resp:
                    if resp.status == 404:
                        stats.not_found += 1
                        progress.advance(task_id)
                        return
                    if resp.status != 200:
                        if attempt == MAX_RETRIES:
                            stats.failed += 1
                            stats.errors.append(f"QB{qid}: HTTP {resp.status}")
                            progress.advance(task_id)
                            return
                        stats.retried += 1
                        await asyncio.sleep(0.5 * (attempt + 1))
                        continue

                    # Stream download into memory
                    chunks = []
                    async for chunk in resp.content.iter_chunked(CHUNK_SIZE):
                        chunks.append(chunk)
                        stats.bytes_downloaded += len(chunk)

                    pdf_bytes = b"".join(chunks)

                # Extract course code from PDF
                course_code = extract_course_code(pdf_bytes)

                if course_code is None:
                    stats.skipped_no_code += 1
                    stats.downloaded += 1
                    progress.advance(task_id)
                    return

                if not course_code.startswith("U"):
                    stats.skipped_non_u += 1
                    stats.downloaded += 1
                    progress.advance(task_id)
                    return

                # Organize into folder
                organize_file(pdf_bytes, course_code, stats)
                stats.downloaded += 1
                progress.advance(task_id)
                return

            except asyncio.TimeoutError:
                if attempt == MAX_RETRIES:
                    stats.failed += 1
                    stats.errors.append(f"QB{qid}: Timeout")
                    progress.advance(task_id)
                    return
                stats.retried += 1
                await asyncio.sleep(1 * (attempt + 1))

            except aiohttp.ClientError as e:
                if attempt == MAX_RETRIES:
                    stats.failed += 1
                    stats.errors.append(f"QB{qid}: {type(e).__name__}")
                    progress.advance(task_id)
                    return
                stats.retried += 1
                await asyncio.sleep(1 * (attempt + 1))

            except Exception as e:
                stats.failed += 1
                stats.errors.append(f"QB{qid}: {type(e).__name__}: {str(e)[:60]}")
                progress.advance(task_id)
                return


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LIVE DASHBOARD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_dashboard(stats: Stats, progress: Progress) -> Table:
    """Build a rich live-updating dashboard."""
    # Main layout
    main_table = Table(
        box=box.DOUBLE_EDGE,
        title="[bold cyan]ğŸ“š KCT Question Bank Downloader[/bold cyan]",
        title_style="bold white",
        show_header=False,
        expand=True,
        padding=(0, 1),
    )
    main_table.add_column(ratio=1)

    # Progress bar row
    main_table.add_row(progress)

    # Stats grid
    grid = Table(box=box.SIMPLE_HEAVY, expand=True, show_header=True)
    grid.add_column("ğŸ“Š Metric", style="bold white", ratio=2)
    grid.add_column("Value", style="bold green", ratio=1, justify="right")
    grid.add_column("ğŸ“Š Metric", style="bold white", ratio=2)
    grid.add_column("Value", style="bold green", ratio=1, justify="right")

    elapsed = stats.elapsed
    mins, secs = divmod(int(elapsed), 60)

    grid.add_row(
        "âœ… Downloaded", f"[green]{stats.downloaded}[/green]",
        "âŒ Not Found (404)", f"[yellow]{stats.not_found}[/yellow]",
    )
    grid.add_row(
        "ğŸ“ Organized (U-codes)", f"[cyan]{stats.organized}[/cyan]",
        "â­ï¸  Skipped (no code)", f"[dim]{stats.skipped_no_code}[/dim]",
    )
    grid.add_row(
        "ğŸ”„ Retried", f"[yellow]{stats.retried}[/yellow]",
        "ğŸ’€ Failed", f"[red]{stats.failed}[/red]",
    )
    grid.add_row(
        "âš¡ Speed", f"[magenta]{stats.speed_mbps:.2f} MB/s[/magenta]",
        "ğŸ“„ Papers/sec", f"[magenta]{stats.papers_per_sec:.1f}[/magenta]",
    )
    grid.add_row(
        "ğŸ’¾ Downloaded", f"[blue]{stats.bytes_downloaded / (1024*1024):.1f} MB[/blue]",
        "â±ï¸  Elapsed", f"[white]{mins}m {secs}s[/white]",
    )
    grid.add_row(
        "ğŸ“ˆ Progress", f"[bold yellow]{stats.progress_pct:.1f}%[/bold yellow]",
        "ğŸ”¢ Total Range", f"[white]{stats.total}[/white]",
    )

    main_table.add_row(grid)

    # Department breakdown (if any organized)
    if stats.dept_counts:
        dept_table = Table(
            box=box.ROUNDED,
            title="[bold]ğŸ›ï¸  Department Breakdown[/bold]",
            expand=True,
            show_header=True,
        )
        dept_table.add_column("Department", style="cyan")
        dept_table.add_column("Count", style="green", justify="right")
        dept_table.add_column("Department", style="cyan")
        dept_table.add_column("Count", style="green", justify="right")

        sorted_depts = sorted(stats.dept_counts.items(), key=lambda x: -x[1])
        # Pair them up for two-column display
        for i in range(0, len(sorted_depts), 2):
            left = sorted_depts[i]
            right = sorted_depts[i + 1] if i + 1 < len(sorted_depts) else ("", "")
            dept_table.add_row(left[0], str(left[1]), str(right[0]), str(right[1]))

        main_table.add_row(dept_table)

    # Regulation breakdown
    if stats.reg_counts:
        reg_parts = [f"[cyan]{r}[/cyan]: [green]{c}[/green]" for r, c in sorted(stats.reg_counts.items())]
        main_table.add_row(Text.from_markup("ğŸ“‹ Regulations: " + " â”‚ ".join(reg_parts)))

    # Recent errors
    if stats.errors:
        last_errors = stats.errors[-3:]
        err_text = " | ".join(f"[red]{e}[/red]" for e in last_errors)
        main_table.add_row(Text.from_markup(f"âš ï¸  Recent errors: {err_text}"))

    return main_table


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ MAIN ORCHESTRATOR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def run():
    """Main async entry point."""
    stats = Stats()
    total_ids = END_ID - START_ID + 1
    stats.total = total_ids

    # Create output directory
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # â”€â”€ PRE-DOWNLOAD SUMMARY â”€â”€
    console.print()
    pre_table = Table(
        title="[bold cyan]ğŸš€ PRE-DOWNLOAD SUMMARY[/bold cyan]",
        box=box.DOUBLE_EDGE,
        show_header=False,
        expand=False,
        padding=(0, 2),
    )
    pre_table.add_column("Metric", style="bold white")
    pre_table.add_column("Value", style="bold green")
    pre_table.add_row("ğŸ“Œ URL Pattern", BASE_URL.format(qid="XXXXX"))
    pre_table.add_row("ğŸ”¢ Range", f"QB{START_ID} â†’ QB{END_ID}")
    pre_table.add_row("ğŸ“„ Total PDFs to check", str(total_ids))
    pre_table.add_row("âš¡ Concurrency", str(MAX_CONCURRENT))
    pre_table.add_row("ğŸ”„ Max retries/PDF", str(MAX_RETRIES))
    pre_table.add_row("ğŸ“‚ Output directory", str(OUTPUT_DIR))
    pre_table.add_row("ğŸ¯ Filter", "Course codes starting with 'U' only")
    pre_table.add_row("ğŸ“ Folder structure", "{Reg}Regulation/{Dept} Department/{Code}.pdf")
    console.print(pre_table)
    console.print()

    # â”€â”€ PROGRESS BAR â”€â”€
    progress = Progress(
        SpinnerColumn("dots"),
        TextColumn("[bold blue]{task.description}"),
        BarColumn(bar_width=50, complete_style="green", finished_style="bold green"),
        MofNCompleteColumn(),
        TextColumn("[yellow]{task.percentage:>5.1f}%"),
        TimeElapsedColumn(),
        TimeRemainingColumn(),
        expand=True,
    )
    task_id = progress.add_task("Downloading & Processing", total=total_ids)

    # â”€â”€ AIOHTTP SESSION â”€â”€
    timeout = aiohttp.ClientTimeout(total=TIMEOUT_SECONDS, connect=10)
    connector = aiohttp.TCPConnector(
        limit=CONNECTOR_LIMIT,
        limit_per_host=CONNECTOR_LIMIT,
        ttl_dns_cache=300,
        enable_cleanup_closed=True,
        force_close=False,
    )

    stats.start_time = time.time()

    async with aiohttp.ClientSession(
        connector=connector,
        timeout=timeout,
        headers={"User-Agent": "KCT-QB-Downloader/2.0"},
    ) as session:
        semaphore = asyncio.Semaphore(MAX_CONCURRENT)

        # â”€â”€ LIVE DASHBOARD â”€â”€
        with Live(
            build_dashboard(stats, progress),
            console=console,
            refresh_per_second=4,
            transient=False,
        ) as live:

            # Process in batches to avoid overwhelming memory
            all_ids = list(range(START_ID, END_ID + 1))

            for batch_start in range(0, len(all_ids), BATCH_SIZE):
                batch = all_ids[batch_start: batch_start + BATCH_SIZE]
                tasks = [
                    download_one(session, qid, semaphore, stats, progress, task_id)
                    for qid in batch
                ]
                await asyncio.gather(*tasks, return_exceptions=True)
                live.update(build_dashboard(stats, progress))

            # Final dashboard update
            live.update(build_dashboard(stats, progress))

    # â”€â”€ POST-DOWNLOAD SUMMARY â”€â”€
    elapsed = stats.elapsed
    mins, secs = divmod(int(elapsed), 60)

    console.print()
    console.print(Panel(
        "[bold green]âœ… DOWNLOAD COMPLETE![/bold green]",
        style="green",
        expand=False,
    ))

    post_table = Table(
        title="[bold cyan]ğŸ“Š FINAL STATISTICS[/bold cyan]",
        box=box.DOUBLE_EDGE,
        show_header=True,
        expand=False,
        padding=(0, 2),
    )
    post_table.add_column("Metric", style="bold white")
    post_table.add_column("Value", style="bold green", justify="right")

    post_table.add_row("ğŸ“„ Total PDFs checked", str(stats.total))
    post_table.add_row("âœ… Successfully downloaded", str(stats.downloaded))
    post_table.add_row("ğŸ“ Organized (U-code papers)", f"[bold cyan]{stats.organized}[/bold cyan]")
    post_table.add_row("âŒ Not found (404)", str(stats.not_found))
    post_table.add_row("â­ï¸  Skipped (no course code)", str(stats.skipped_no_code))
    post_table.add_row("â­ï¸  Skipped (non-U code)", str(stats.skipped_non_u))
    post_table.add_row("ğŸ’€ Failed", f"[red]{stats.failed}[/red]")
    post_table.add_row("ğŸ”„ Total retries", str(stats.retried))
    post_table.add_row("ğŸ’¾ Total data downloaded", f"{stats.bytes_downloaded / (1024*1024):.2f} MB")
    post_table.add_row("â±ï¸  Total time", f"{mins}m {secs}s")
    post_table.add_row("âš¡ Avg speed", f"{stats.speed_mbps:.2f} MB/s")
    post_table.add_row("ğŸ“„ Avg papers/sec", f"{stats.papers_per_sec:.1f}")
    console.print(post_table)

    # Department summary
    if stats.dept_counts:
        console.print()
        dept_table = Table(
            title="[bold cyan]ğŸ›ï¸  PAPERS BY DEPARTMENT[/bold cyan]",
            box=box.ROUNDED,
            show_header=True,
        )
        dept_table.add_column("#", style="dim", justify="right")
        dept_table.add_column("Department", style="cyan")
        dept_table.add_column("Papers", style="green", justify="right")

        for idx, (dept, count) in enumerate(
            sorted(stats.dept_counts.items(), key=lambda x: -x[1]), 1
        ):
            dept_table.add_row(str(idx), dept, str(count))
        console.print(dept_table)

    # Regulation summary
    if stats.reg_counts:
        console.print()
        reg_table = Table(
            title="[bold cyan]ğŸ“‹ PAPERS BY REGULATION[/bold cyan]",
            box=box.ROUNDED,
            show_header=True,
        )
        reg_table.add_column("Regulation", style="cyan")
        reg_table.add_column("Papers", style="green", justify="right")
        for reg, count in sorted(stats.reg_counts.items()):
            reg_table.add_row(reg, str(count))
        console.print(reg_table)

    # Folder tree preview
    if stats.organized > 0:
        console.print()
        console.print("[bold cyan]ğŸ“‚ OUTPUT FOLDER STRUCTURE:[/bold cyan]")
        console.print(f"   [dim]{OUTPUT_DIR}/[/dim]")
        for reg_dir in sorted(OUTPUT_DIR.iterdir()):
            if reg_dir.is_dir():
                console.print(f"   â”œâ”€â”€ [yellow]{reg_dir.name}/[/yellow]")
                dept_dirs = sorted(reg_dir.iterdir())
                for i, dept_dir in enumerate(dept_dirs):
                    if dept_dir.is_dir():
                        files = list(dept_dir.glob("*.pdf"))
                        branch = "â””â”€â”€" if i == len(dept_dirs) - 1 else "â”œâ”€â”€"
                        console.print(f"   â”‚   {branch} [cyan]{dept_dir.name}/[/cyan] ({len(files)} papers)")

    # Error log
    if stats.errors:
        console.print()
        console.print(f"[yellow]âš ï¸  {len(stats.errors)} errors encountered. First 10:[/yellow]")
        for err in stats.errors[:10]:
            console.print(f"   [red]â€¢ {err}[/red]")

    console.print()
    console.print("[bold green]ğŸ‰ All done! Papers organized in:[/bold green]", str(OUTPUT_DIR))
    console.print()


def main():
    """Entry point."""
    try:
        asyncio.run(run())
    except KeyboardInterrupt:
        console.print("\n[yellow]âš ï¸  Interrupted by user. Partial results saved.[/yellow]")
        sys.exit(1)


if __name__ == "__main__":
    main()
